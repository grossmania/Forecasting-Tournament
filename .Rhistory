xend=Category,
y=0,
yend=Percent)) + theme(legend.position="top")+
scale_color_aaas()+ labs(colour = "Morals Necessary\nfor Wisdom",x="",y="% of the Sample") +scale_x_discrete(labels=labels, name="")
Moral.open.Summary.Mness %>% arrange(Percent) %>%
ggplot(aes(x=Category, y=Percent)) +
geom_point(col="tomato2", size=3) +   # Draw points
geom_segment(aes(x=Category,
xend=Category,
y=min(Percent),
yend=max(Percent)),
linetype="dashed",
size=0.1) + theme_minimal()+ facet_wrap(vars(M2W_Necessary))+ # Draw dashed lines
coord_flip()+scale_color_aaas()+scale_x_discrete(labels=labels, name="")+coord_flip()
ggplot(Moral.open.Summary.Mness, aes(x=Category, y=Percent, color=as.factor(M2W_Necessary))) +
geom_point(size=3, position=pd) +
geom_segment(aes(x=Category,
xend=Category,
y=0,
yend=Percent)) + theme(legend.position="top")+
scale_color_aaas()+ labs(colour = "Morals Necessary\nfor Wisdom",x="",y="% of the Sample") +scale_x_discrete(labels=labels, name="")+coord_flip()
ggplot(Moral.open.Summary.Mness, aes(x=Category, y=Percent, color=as.factor(M2W_Necessary))) +
geom_point(size=3, position=pd) +
geom_segment(aes(x=Category,
xend=Category,
y=0,
yend=Percent)) + theme(legend.position="top")+
scale_color_aaas()+ labs(colour = "Morals Necessary\nfor Wisdom",x="",y="% of the Sample") +scale_x_discrete(labels=labels, name="")+coord_flip()
Moral.open.Summary.Wness<-Moral.open.long %>%
group_by(Category,W2M_Necessary) %>%
summarise(Prop = mean(Score, na.rm=T)) %>%
mutate(Percent = Prop*100) %>% ungroup() %>%  arrange(Percent)
ggplot(Moral.open.Summary.Wness, aes(x=Category, y=Percent, color=as.factor(W2M_Necessary))) +
geom_point(size=3, position=pd) +
geom_segment(aes(x=Category,
xend=Category,
y=0,
yend=Percent)) + theme(legend.position="top")+
scale_color_aaas()+ labs(colour = "Wisdom Necessary\nfor Morality",x="",y="% of the Sample") +scale_x_discrete(labels=labels, name="")+coord_flip()
ggplot(Moral.open.Summary.Wness, aes(x=Category, y=Percent, color=as.factor(W2M_Necessary))) +
geom_point(size=3, position=pd) +
geom_segment(aes(x=Category,
xend=Category,
y=0,
yend=Percent)) + theme(legend.position="top")+
scale_color_aaas()+ labs(colour = "Wisdom Necessary\nfor Morality",x="",y="% of the Sample") +scale_x_discrete(labels=labels, name="")+coord_flip()
Moral.open.Summary.Mrel<-Moral.open.long %>%
group_by(Category,M2W_Relevant) %>%
summarise(Prop = mean(Score, na.rm=T)) %>%
mutate(Percent = Prop*100) %>% ungroup() %>%  arrange(Percent)
ggplot(Moral.open.Summary.Mrel, aes(x=Category, y=Percent, color=as.factor(M2W_Relevant))) +
geom_point(size=3, position=pd) +
geom_segment(aes(x=Category,
xend=Category,
y=0,
yend=Percent)) + theme(legend.position="top")+
scale_color_aaas()+ labs(colour = "Morals Relevant\nfor Wisdom",x="",y="% of the Sample") +scale_x_discrete(labels=labels, name="")+coord_flip()
ggplot(Moral.open.Summary.Mrel, aes(x=Category, y=Percent, color=as.factor(M2W_Relevant))) +
geom_point(size=3, position=pd) +
geom_segment(aes(x=Category,
xend=Category,
y=0,
yend=Percent)) + theme(legend.position="top")+
scale_color_aaas()+ labs(colour = "Morals Relevant\nfor Wisdom",x="",y="% of the Sample") +scale_x_discrete(labels=labels, name="")+coord_flip()
WisMor.long
View(WisMor.long)
glmer.morals.pWisdom<-glmer(Proportion~Group.F*Category*prior_research+ (1|ResponseId),data =WisMor.long, family=binomial(link="logit") )
Anova(glmer.morals.pWisdom,type=3)
glmer.morals.pMorals<-glmer(Proportion~Group.F*Category*research_morality+ (1|ResponseId),data =WisMor.long, family=binomial(link="logit") )
Anova(glmer.morals.pWisdom,type=3)
Anova(glmer.morals.pCulture,type=3)
glmer.morals.pCulture<-glmer(Proportion~Group.F*Category*research_culturalpsy+ (1|ResponseId),data =WisMor.long, family=binomial(link="logit") )
Anova(glmer.morals.pCulture,type=3)
#Adding Variables ----
total <- total %>% filter(!grepl("progress",Progress, ignore.case = TRUE)) %>%
rename(Duration=Duration..in.seconds.)
#Importing Packages, Data----
rm(list=ls())
library(tidyverse)
library(tm)
library(stringr)
library(tidytext)
library(kableExtra)
library(ggplot2)
library(kableExtra)
library(ggsci)
library(vcd)
library(lme4)
library(emmeans)
library(jtools)
library(sjPlot)
library(car)
setwd("~/GitHub/wisdom-summit-2021")
raw <- read.csv('Wisdom_Summit_Sept_21_2021.csv')
culture<-read.csv('culture.csv')
morality<-read.csv('morality.csv')
total<-raw %>% left_join(culture) %>% left_join(morality)
#Adding Variables ----
total <- total %>% filter(!grepl("progress",Progress, ignore.case = TRUE)) %>%
rename(Duration=Duration..in.seconds.)
total$Duration <- as.numeric(total$Duration)
total <- total %>%
mutate(filter = ifelse(str_detect(wisdom_culture, "useless|1"), 1, 0)) %>%
mutate(filter = ifelse(!is.na(country) & str_detect(country, "TEST"), 1, filter)) %>%
mutate(filter = ifelse(!is.na(country) & str_detect(country, "test"), 1, filter)) %>%
mutate(filter = ifelse(Duration < 30, 1, filter)) #if they spent less than 30 seconds, remove them
total$filter <- as.factor(total$filter)
# summary(raw$filter)
data <- total %>% filter(filter==0)
data <- data %>%
mutate(position2 = ifelse(position == "Other" &
str_detect(position_8_TEXT,"Lecturer|Emeritus|senior lecturer|On sabbatical"),
"Professor",position))%>%
mutate(position2 = ifelse(position == "Other" &
str_detect(position_8_TEXT, "PhD scholar|RA|scientist|psychologist|Associate"),
"Graduate Student",position2))
# data%>%filter(position == "Other") %>% select(position,position_8_TEXT, education, position2)
USlist <- c("US", "us", "Usa", "United States of America","united States", "United States", "The United States of America")
UKlist <- c("UK","united kingdom", "United Kingdom", "England")
data$country <- data$country %>% str_trim()
data <- data %>%
mutate(country = ifelse(country %in% USlist,"USA", country))%>%
mutate(country = ifelse(country %in% UKlist, "UK", country))%>%
mutate(country = ifelse(country =="BG", "Bulgaria", country)) %>%
mutate(country = ifelse(country =="CHINA", "China", country)) %>%
mutate(country = ifelse(country =="canada", "Canada", country)) %>%
mutate(country = ifelse(country == "HK", "China", country)) %>%
mutate(country = ifelse(country == "Hong Kong", "China", country)) %>%
mutate(country = ifelse(country == "Russian Federation", "Russia", country)) %>%
mutate(country = ifelse(country == "Nederland", "Netherlands", country)) %>%
mutate(country = ifelse(country == "philippines", "Philippines", country)) %>%
mutate(country = ifelse(country == "Hong Kong S.A.R. / China", "China", country)) %>%
mutate(country = ifelse(country == "Viet Nam", "Vietnam", country)) %>%
mutate(country = ifelse(country == "turkey", "Turkey", country))
data <- data %>%
mutate(position2= ifelse(str_detect(position2,"Professor"), "Professor", "Not a Professor"))
data <- data %>%
mutate(CountryCode= ifelse(str_detect(country,"USA|Canada"), "USA & Canada", "Others"))
cols <- c("country","CountryCode","position","position2")
data[,cols] <- lapply(data[,cols],as.factor)
#Subset Data & No Of Answers ----
data <- data %>%
mutate_all(na_if,"")
data <- data %>%
mutate(Social = ifelse(str_detect(field, "Social Psychology"), 1, 0))%>%
mutate(Moral_Psychology = ifelse(str_detect(field, "Moral Psychology"), 1, 0))%>%
mutate(Wisdom = ifelse(str_detect(field, "Wisdom"), 1, 0))%>%
mutate(Clinical = ifelse(str_detect(field, "Clinical"), 1, 0))%>%
mutate(Personality  = ifelse(str_detect(field, "Personality"), 1, 0))%>%
mutate(Education = ifelse(str_detect(field, "Education"), 1, 0))%>%
mutate(Developmental = ifelse(str_detect(field, "Developmental"), 1, 0))%>%
mutate(CogSci = ifelse(str_detect(field, "Cognitive Science"), 1, 0))%>%
mutate(Cognitive = ifelse(str_detect(field, "Cognitive Psychology"), 1, 0))%>%
mutate(Quantitative = ifelse(str_detect(field, "Quantitative Psychology"), 1, 0))%>%
mutate(Evolutionary = ifelse(str_detect(field, "Evolutionary Psychology"), 1, 0))%>%
mutate(Moral_philosophy = ifelse(str_detect(field, "Moral philosophy"), 1, ifelse(str_detect(field, "Virtue"), 1, 0)))%>%
mutate(Virtue = ifelse(str_detect(field, "Virtue"), 1, 0))
data.filter<-data %>%
filter(!is.na(morality_wis_analogy) |
!is.na(moral_wis_comments) |
!is.na(wis_psych_char) |
!is.na(model_agreement) |
!is.na(model_disagree) |
!is.na(wisdom_culture)|
!is.na(comments)) %>%
rename(Position = position2, Field = field)
#country
data.filter%>%
group_by(country) %>%
summarise(tally = n()) %>%
arrange(desc(tally)) %>%
mutate(country = fct_reorder(country, tally)) %>%
ggplot(aes(x=country, y=tally)) +
geom_bar(stat="identity", alpha=.6, width=.4) +
coord_flip() +labs(x="",y="Count") +theme_minimal()
data.filter %>%
ggplot(aes(x = country)) + geom_histogram(stat="count")+coord_flip()
data.filter %>%
ggplot(aes(x = country)) + geom_histogram(stat="count")+coord_flip()
data.filter%>%
group_by(country) %>%
summarise(tally = n()) %>%
arrange(desc(tally)) %>%
mutate(country = fct_reorder(country, tally)) %>%
ggplot(aes(x=country, y=tally)) +
geom_bar(stat="identity", alpha=.6, width=.4) +
coord_flip() +labs(x="",y="Count") +theme_minimal()
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE, fig.width = 12
)
#load packages
library(dplyr)
library(tidyr) #drop_na
library(car)
library(DT)
library(psych) #scatterHist
library(emmeans)
library(ggplot2)
library(ggthemes)
library(pwr)
library(ggsci)
library(readr)
library(lavaan)
#read marged file created by KS Includes trust game measures (created by AD) and D1 composites (created by KS). Event categories coded by MKY
All.waves<-read_csv("PHLandLKAcombined.csv")
data.swis<-read_csv("PHLandLKAcombined.csv")
data.swis[data.swis=="Strongly agree"]<-5
data.swis<-read_csv("PHLandLKAcombined.corr.csv")
names(data.swis)
#subset
data.swis.clean<-subset(data.swis,Include/Exclude=="Include")
#subset
data.swis.clean<-subset(data.swis,`Include/Exclude`=="Include")
table(data.swis.clean$Country)
View(data.swis.clean)
table(data.swis$Country)
swis.model<-
"Perspective =~ EnrichedSWIS01+EnrichedSWIS02+EnrichedSWIS03+EnrichedSWIS04
Change=~ EnrichedSWIS05+EnrichedSWIS06+EnrichedSWIS07+EnrichedSWIS08
Limits =~EnrichedSWIS09+EnrichedSWIS10+EnrichedSWIS11+EnrichedSWIS12
Compromise =~EnrichedSWIS13+EnrichedSWIS14+EnrichedSWIS15+EnrichedSWIS16+EnrichedSWIS17
Outsider =~EnrichedSWIS18+EnrichedSWIS19+EnrichedSWIS20+EnrichedSWIS21"
model.cfa <- cfa(swis.model, std.lv = TRUE, data = data.swis.clean, missing='fiml')
summary(model.cfa, nd= 4,fit.measures = T, standardized = T)
modindices(model.cfa,minimum.value = 10, sort = TRUE)
config <- cfa(swis.model, data=all, group="Country")
config <- cfa(swis.model, data=data.swis.clean, group="Country")
summary(config, nd= 4,fit.measures = T, standardized = T)
weak <- cfa(swis.model, data=data.swis.clean, group="Country",
group.equal = c("loadings"))
summary(weak, nd= 4,fit.measures = T, standardized = T)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE, fig.width = 12
)
#load packages
library(dplyr)
library(tidyr) #drop_na
library(car)
library(DT)
library(psych) #scatterHist
library(GPArotation)
library(emmeans)
library(ggplot2)
library(ggthemes)
library(ggsci)
library(readr)
library(lavaan)
data.swis<-read_csv("PHLandLKAcombined.corr.csv")
#subset
data.swis.clean<-subset(data.swis,`Include/Exclude`=="Include")
eightfactor.LKA<-data.swis.clean %>% filter(Country=="LKA") %>%
select(starts_with("EnrichedSWIS")) %>% fa(nfactors = 8,rotate = "oblimin",fm="minres")
print(eightfactor.LKA)
print(eightfactor.LKA$loadings)
#even easier to interpet
print(eightfactor.LKA$loadings,cutoff = 0.3)
eightfactor.PHL<-data.swis.clean %>% filter(Country=="PHL") %>%
select(starts_with("EnrichedSWIS")) %>% fa(nfactors = 8,rotate = "oblimin",fm="minres")
print(eightfactor.PHL)
print(eightfactor.PHL$loadings)
#even easier to interpet
print(eightfactor.PHL$loadings,cutoff = 0.3)
data.swis.clean$Perspective <- (rowMeans(data.swis.clean[,c(EnrichedSWIS01:EnrichedSWIS04] , na.rm = T))
data.swis.clean$Perspective <- (rowMeans(data.swis.clean[EnrichedSWIS01:EnrichedSWIS04] , na.rm = T))
data.swis.clean$Perspective <- (rowMeans(data.swis.clean[c(EnrichedSWIS01:EnrichedSWIS04)] , na.rm = T))
data.swis.clean$Perspective <- (rowMeans(data.swis.clean[c("EnrichedSWIS01":"EnrichedSWIS04")] , na.rm = T))
data.swis.clean$Perspective <- (rowMeans(data.swis.clean[c("EnrichedSWIS01","EnrichedSWIS02",
"EnrichedSWIS03","EnrichedSWIS04")] , na.rm = T))
data.swis.clean$Change <- (rowMeans(data.swis.clean[c("EnrichedSWIS05","EnrichedSWIS06",
"EnrichedSWIS07","EnrichedSWIS08")] , na.rm = T))
data.swis.clean$Limits <- (rowMeans(data.swis.clean[c("EnrichedSWIS09","EnrichedSWIS10",
"EnrichedSWIS11","EnrichedSWIS12")] , na.rm = T))
data.swis.clean$Compromise <- (rowMeans(data.swis.clean[c("EnrichedSWIS13","EnrichedSWIS14",
"EnrichedSWIS15","EnrichedSWIS16","EnrichedSWIS17")] , na.rm = T))
data.swis.clean$Outsider <- (rowMeans(data.swis.clean[c("EnrichedSWIS18","EnrichedSWIS19",
"EnrichedSWIS20","EnrichedSWIS21")] , na.rm = T))
?correlation::correlation()
library(correlation)
correlation(select(Perspective:Outsider),select(EnrichedSWIS22:EnrichedSWIS57)
)
data.swis.clean %>%
correlation(select(Perspective:Outsider),select(EnrichedSWIS22:EnrichedSWIS57))
correlation(select(data.swis.clean,Perspective:Outsider),select(data.swis.clean,EnrichedSWIS22:EnrichedSWIS57))
plot(correlation(select(data.swis.clean,Perspective:Outsider),select(data.swis.clean,EnrichedSWIS22:EnrichedSWIS57)))
library(ggraph)
plot(correlation(select(data.swis.clean,Perspective:Outsider),select(data.swis.clean,EnrichedSWIS22:EnrichedSWIS57)))
#Lanka
data.swis.clean %>% filter(Country=="PHL") %>%
correlation(select(Perspective:Outsider),select(EnrichedSWIS22:EnrichedSWIS57))
#Lanka
data.swis.clean %>% filter(Country=="PHL") %>%
correlation(select(filter(data.swis.clean,Country=="PHL"),Perspective:Outsider),select(data.swis.clean,EnrichedSWIS22:EnrichedSWIS57))
#Lanka
correlation(select(filter(data.swis.clean,Country=="PHL"),Perspective:Outsider),select(filter(data.swis.clean,Country=="PHL"),EnrichedSWIS22:EnrichedSWIS57))
#Lanka
correlation(select(filter(data.swis.clean,Country=="LKA"),Perspective:Outsider),select(filter(data.swis.clean,Country=="LKA"),EnrichedSWIS22:EnrichedSWIS57))
?fa
?plot_summs
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(psych)
library(tidyverse)
library(stats) #to get p.adjust
library(irr)
library(lme4)
library(ggplot2)
library(tidyr)
library(emmeans)
library(car)
library(jtools)
library(dplyr)
library(ggsci)
library(dplyr)
library(Hmisc)
library(lubridate)
library(statcomp) #to get complexity measures for time series
library(tsibble) #to converte into time series tibble for tidy analyses
#install.packages("CGPfunctions")
library(CGPfunctions) #to graph change in trends over time.
library(partR2) #to get partR2 for LME models
library(moments) #to get skewness
library(ggpubr) #to combine plots
#library(simr) # to simulate power - not useful in posthoc designs
library(rstanarm) #to get bayesian equivalent of difference tests
library(bayestestR) #to get BayesF factor from BIC scores of different lmer models
options(max.print = 20000, scipen = 1000)
setwd("~/GitHub/Forecasting-Tournament") #igor's working directory
dat <- read.csv("dat_for_analyses.csv", stringsAsFactors = FALSE)
dat_long <- read.csv("dat_long.csv", stringsAsFactors = FALSE)
#add simulation benchmarks
load("sim/BenchmarkData_Combined.RData")
sim.w1 <- Stats_all_benchmarks_raw
sim.w1$Wave <-"First Tournament (May 2020)"
sim.w1 <- subset(sim.w1,source!="Experts"&source!="Lay People")
sim.w1$response <- sim.w1$Mean
sim.w1$lower.CL <- sim.w1$CI_L
sim.w1$upper.CL <- sim.w1$CI_U
sim.w1$Type[sim.w1$source=="Benchmark 1"]<-"Historic Mean"
sim.w1$Type[sim.w1$source=="Benchmark 2"]<-"Random Walk"
sim.w1$Type[sim.w1$source=="Benchmark 3"]<-"Linear Regression"
load("sim/BenchmarkData_Combined_W2.RData")
sim.w2<-Stats_all_benchmarks_raw_w2
sim.w2$Wave<-"Second Tournament (Nov 2020)"
sim.w2<-subset(sim.w2,source!="ExpertsW2")
sim.w2$response<-sim.w2$Mean
sim.w2$lower.CL<-sim.w2$CI_L
sim.w2$upper.CL<-sim.w2$CI_U
sim.w2$Type[sim.w1$source=="Benchmark 1"]<-"Historic Mean"
sim.w2$Type[sim.w1$source=="Benchmark 2"]<-"Random Walk"
sim.w2$Type[sim.w1$source=="Benchmark 3"]<-"Linear Regression"
#get simulation-based random walk cut-offs - to be used for inspection of top teams
#ADD PART how to use RW SIM scores per domain per wave to get the cutoff scores.
##
#subset benchmark, first
sim.w1.rw <- sim.w1 %>%
filter(Type == 'Random Walk') %>%
mutate(rw.MASE.w1 = response) %>%
dplyr::select(domain, rw.MASE.w1)
sim.w2.rw <- sim.w2 %>%
filter(Type == 'Random Walk') %>%
mutate(rw.MASE.w2 = response) %>%
dplyr::select(domain, rw.MASE.w2)
##
## add to the datafile
dat <- dat %>%
left_join(sim.w1.rw)
dat <- dat %>%
left_join(sim.w2.rw)
## create cut-offs
dat$compare_to_naive_rwf_MASE<-NA #first set to NA
dat<-dat %>% #create difference score between MASE of estimate and RW MASE
mutate(diff_to_naive_rwf_MASE = case_when(
phase==1 ~ MASE1_w1 - rw.MASE.w1 ,
phase==2 ~ MASE1_w2 - rw.MASE.w2
))
#check number of NAs
#View(dat[is.na(dat$diff_to_naive_rwf_MASE),c("ResponseId", "team_name", "domain", "compare_to_naive_rwf","phase", "Month.1" ,
#                                            "Month.2" ,"Month.3" ,"Month.4" ,"Month.5" ,"Month.6","Month.7",
#                                           "Month.8" ,"Month.9" ,"Month.10" ,"Month.11" ,"Month.12","MASE1_w2", "rw.MASE.w2")])
dat<-dat %>% #use the diff score values to calculate the cut offs (for graphs) later on
mutate(compare_to_naive_rwf_MASE = case_when(
diff_to_naive_rwf_MASE < 1 ~ "Below Random Walk",
diff_to_naive_rwf_MASE == 1 ~ "Equal to Random Walk",
diff_to_naive_rwf_MASE > 1 ~ "Above Random Walk"
))
#cross-check data for NAs
#View(dat[is.na(dat$compare_to_naive_rwf_MASE),c("ResponseId", "team_name", "domain", "compare_to_naive_rwf","phase","Month.1" ,
#                                            "Month.2" ,"Month.3" ,"Month.4" ,"Month.5" ,"Month.6","Month.7",
#                                            "Month.8" ,"Month.9" ,"Month.10" ,"Month.11" ,"Month.12" ,                                           "MASE1_w1", "rw.MASE.w1")])
# dataset that only includes academic predictions and those who provided open-ended data
academic_only <- filter(dat, isExpert == 1 )
# View(dat[,c("ResponseId", "team_name", "isExpert", "MASE1_w2", "MASE1_w2")])
#note that missing NAs for isExpert at the end of the file is by design,  these are naÃ¯ve benchmark estimates
#datasets that are filtered by phase (1 = May submission, 2 = November submission)
phase1 <- filter(dat, phase == 1)
phase2 <- filter(dat, phase == 2)
# Phase 1 & 2 further filtered to only include academics won't be necessary once we have updated objective data
phase1_exp <- filter(phase1, isExpert == 1)
phase2_exp <- filter(phase2, isExpert == 1)
objective <- dat %>%
filter(Method == "Objective", phase == 1) %>%
dplyr::select(domain:Month.12)
psych::describe(phase1.noexp.dem$Age)
phase1.noexp.dem<-phase1 %>% filter(isExpert.factor=="Prolific") %>% dplyr::select(ResponseId,Age, Sex, Ethnicity, Education,Residential.Area, Income) %>% dplyr::group_by(ResponseId) %>%
summarize_all(~ mean(.x, na.rm = TRUE))
psych::describe(phase1.noexp.dem$Age)
prop.table(table(phase1.noexp$Sex)) #46.36% female
prop.table(table(phase1.noexp.dem$Sex)) #46.36% female
prop.table(table(phase1.noexp.dem$Education))
#"1 =  less than highschool
#2 =  highschool grad
#3 =  some college
#4 =  vocational/technical degree
#5 =  bachelor's
#6 =  masters'
#7 =  doctorate
#8 =  professional degree"
0.416846652+ 0.162706983+ 0.017278618+ 0.029517639 #proportion with a college degree or above
prop.table(table(phase1.noexp.dem$Education))
table(phase1.noexp.dem$Education)
psych::describe(phase1_exp$team_Age)
psych::describe(dat_phase2$team_Age)
#phase 2
dat_phase2<-academic_only %>%filter(!(phase == 1 & revised == 1)) #just academics, omitting original (non-revised phase 1)
#total percentage in the tournament without a PhD
##multiple % per team without a PhD by number of team members and subtract from 1 and multiple by 100 to get % of forecasts done by PhDs
(1 - sum(phase1_exp$team_education/100*phase1_exp$team_size.coded)/sum(phase1_exp$team_size.coded))*100
#total percentage in the tournament without a PhD
table(phase1_exp$team_education)
##multiple % per team without a PhD by number of team members and subtract from 1 and multiple by 100 to get % of forecasts done by PhDs
(1 - sum(phase1_exp$team_education/100*phase1_exp$team_size.coded)/sum(phase1_exp$team_size.coded))*100
(1 - sum(dat_phase2$team_education/100*dat_phase2$team_size.coded)/sum(dat_phase2$team_size.coded))*100
#age
table(phase1_exp$team_Age)
#age
psych::describe(phase1_exp$team_Age)
#gender
psych::describe(phase1_exp$team_gender)
#gender
table(phase1_exp$team_gender)
#gender: Percentage of team members who indicated their gender was either Female or Other
psych::describe(phase1_exp$team_gender)
(1 - sum(phase1_exp$team_gender/100*phase1_exp$team_size.coded)/sum(phase1_exp$team_size.coded))*100
sum(phase1_exp$team_size.coded)
sum(phase1_exp$team_gender/100*phase1_exp$team_size.coded)
(1 - sum(phase1_exp$team_gender/100*phase1_exp$team_size.coded)/sum(phase1_exp$team_size.coded))*100
(1 - sum(dat_phase2$team_gender/100*dat_phase2$team_size.coded)/sum(dat_phase2$team_size.coded))*100
(sum(phase1_exp$non_US/100*phase1_exp$team_size.coded)/sum(phase1_exp$team_size.coded))*100
table(phase1_exp$non_US)
table(phase1_exp$team_size.coded)
phase1$isExpert.factor
table(phase1$team_name)
phase1.exp.dem<-phase1 %>% filter(isExpert.factor=="Academic") %>% dplyr::select(team_name, team_size.coded, n_domains,team_Age,team_education,non_US,team_gender,revised) %>% dplyr::group_by(team_name) %>%
summarize_all(~ mean(.x, na.rm = TRUE))
#count how many domains per person
phase1_exp<-phase1_exp %>%group_by(team_name) %>%
mutate(n_domains = n())
#count how many domains per person
phase1_exp<-phase1_exp %>%group_by(team_name) %>%  mutate(n_domains = n())
#count how many domains per person
dat_phase2<-dat_phase2 %>%group_by(team_name) %>%  mutate(n_domains = n())
phase1.exp.dem<-phase1 %>% filter(isExpert.factor=="Academic") %>% dplyr::select(team_name, team_size.coded, n_domains,team_Age,team_education,non_US,team_gender,revised) %>% dplyr::group_by(team_name) %>%
summarize_all(~ mean(.x, na.rm = TRUE))
phase1.exp.dem<-phase1_exp %>% dplyr::select(team_name, team_size.coded, n_domains,team_Age,team_education,non_US,team_gender,revised) %>% dplyr::group_by(team_name) %>%
summarize_all(~ mean(.x, na.rm = TRUE))
View(phase1.exp.dem)
phase2.exp.dem<-dat_phase2 %>% dplyr::select(team_name, team_size.coded, n_domains,team_Age,team_education,non_US,team_gender,revised) %>% dplyr::group_by(team_name) %>%
summarize_all(~ mean(.x, na.rm = TRUE))
#number of participants
sum(phase1.exp.dem$team_size.coded)
sum(phase2.exp.dem$team_size.coded)
#team size
psych::describe(phase1.exp.dem$team_size.coded)
psych::describe(phase2.exp.dem$team_size.coded)
#n forecasted domains
psych::describe(phase1.exp.dem$n_domains)
psych::describe(phase2.exp.dem$n_domains)
#age
psych::describe(phase1.exp.dem$team_Age)
psych::describe(phase2.exp.dem$team_Age)
#Percentage of team members who indicated their level of education was not PhD
psych::describe(phase1.exp.dem$team_education)
psych::describe(phase2.exp.dem$team_education)
##multiple % per team without a PhD by number of team members and subtract from 1 and multiple by 100 to get % of forecasts done by PhDs
(1 - sum(phase1.exp.dem$team_education/100*phase1.exp.dem$team_size.coded)/sum(phase1.exp.dem$team_size.coded))*100
(1 - sum(phase2.exp.dem$team_education/100*phase2.exp.dem$team_size.coded)/sum(phase2.exp.dem$team_size.coded))*100
#gender: Percentage of team members who indicated their gender was either Female or Other
psych::describe(phase1.exp.dem$team_gender)
psych::describe(phase2.exp.dem$team_gender)
#male phase 1
(1 - sum(phase1.exp.dem$team_gender/100*phase1.exp.dem$team_size.coded)/sum(phase1.exp.dem$team_size.coded))*100
(1 - sum(phase2.exp.dem$team_gender/100*phase2.exp.dem$team_size.coded)/sum(phase2.exp.dem$team_size.coded))*100
# non-US Percentage of team members who indicated their country of residence was not the United States
psych::describe(phase1.exp.dem$non_US)
psych::describe(phase2.exp.dem$non_US)
(sum(phase1.exp.dem$non_US/100*phase1.exp.dem$team_size.coded)/sum(phase1.exp.dem$team_size.coded))*100
(sum(phase2.exp.dem$non_US/100*phase2.exp.dem$team_size.coded)/sum(phase2.exp.dem$team_size.coded))*100
psych::describe(phase1.exp.dem$revised*100)
psych::describe(phase2.exp.dem$revised*100)
#did preference for updating vary by method?
model.revised.t1.by.method<-glmer(revised~method.contrast+(1|team_name), data=phase1_exp, family=binomial)
## we test if forecasts that considered historical data as part of the forecast modelling were more accurate than models that did not - MAIN TEXT
#i.e., EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
### Tournament 1
phase1_exp$method.contrast<-ifelse(phase1_exp$Method.code=='Intuition/Theory',0,1)
#did preference for updating vary by method?
model.revised.t1.by.method<-glmer(revised~method.contrast+(1|team_name), data=phase1_exp, family=binomial)
summ(model.revised.t1.by.method, conf.method="boot", digits=3, center=T)
